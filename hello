{
  "paragraphs": [
    {
      "text": "%sh\njps -m",
      "user": "namratas@qubole.com",
      "dateUpdated": "Mar 23, 2020 12:45:43 PM",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "hideControlBar": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "20546 NameNode\n23492 ResourceManager\n31942 MetricsApplication server /usr/lib/metricsd/config/config.yaml\n28583 HistoryServer\n30057 RunJar /usr/lib/rubix/lib/rubix-bookkeeper-0.3.6-SNAPSHOT.jar com.qubole.rubix.bookkeeper.BookKeeperServer -Drubix.cluster.is-master\u003dtrue -Drubix.validation.enabled\u003dfalse -Drubix.cluster.type\u003d0\n26506 JobHistoryServer\n24046 ApplicationHistoryServer\n7856 RemoteInterpreterServer 10.182.196.34 43399 :\n13712 RunJar /usr/lib/hive1.2/lib/hive-service-1.2.0-qds-1.0.3-SNAPSHOT.jar org.apache.hadoop.hive.metastore.HiveMetaStore -hiveconf hive.metastore.warehouse.dir\u003ds3://dev.canopydata.com/namratas/qib/warehouse -hiveconf hive.metastore.execute.setugi\u003dfalse -hiveconf fs.s3.awsSecretAccessKey\u003dVIW1Xt5zjcM34YhXY3IbrTmjgjN3YqIQLcXQkyxB -hiveconf fs.s3.isClusterOnEc2Role\u003dfalse -hiveconf fs.s3n.awsSecretAccessKey\u003dVIW1Xt5zjcM34YhXY3IbrTmjgjN3YqIQLcXQkyxB -hiveconf fs.s3n.isClusterOnEc2Role\u003dfalse -hiveconf hive.log.file\u003dhive_ms.log -hiveconf hive.log4j.file\u003d/usr/lib/hive1.2/conf/hive-log4j.properties -hiveconf javax.jdo.option.ConnectionDriverName\u003dcom.mysql.jdbc.Driver -hiveconf javax.jdo.option.ConnectionPassword\u003dEGDJF34H -hiveconf fs.s3.awsAccessKeyId\u003dAKIAJ5DKXANHSDQDJ6QA -hiveconf javax.jdo.option.ConnectionUserName\u003dhu_85 -hiveconf fs.s3n.awsAccessKeyId\u003dAKIAJ5DKXANHSDQDJ6QA -hiveconf javax.jdo.option.ConnectionURL\u003djdbc:mysql://127.0.0.1:7000/metastore_85\n29366 gateway.jar\n30071 RunJar /usr/lib/rubix/lib/rubix-bookkeeper-0.3.6-SNAPSHOT.jar com.qubole.rubix.bookkeeper.LocalDataTransferServer\n29754 jetty-runner.jar --port 10500 /usr/lib/tez/tez-ui/tez-ui-0.7.0-qds-1.6-SNAPSHOT.war --log /media/ephemeral0/logs/others/tez-ui.log --out /media/ephemeral0/logs/others/tez-ui.out\n16474 QuboleD\n24219 NGServer\n28283 LivyServer\n19708 ZeppelinServer\n12799 Jps -m\n"
          }
        ]
      },
      "apps": [],
      "version": "v1",
      "jobName": "paragraph_1584967380596_2000486105",
      "id": "20200323-124300_1203236960_q_6WKZYWQP1W1584967376",
      "dateCreated": "Mar 23, 2020 12:42:56 PM",
      "dateSubmitted": "Mar 23, 2020 12:45:43 PM",
      "dateStarted": "Mar 23, 2020 12:45:43 PM",
      "dateFinished": "Mar 23, 2020 12:45:43 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 1000
    },
    {
      "text": "%sh\n",
      "user": "namratas@qubole.com",
      "dateUpdated": "Mar 23, 2020 12:45:05 PM",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "version": "v0",
      "jobName": "paragraph_1584967505413_-1071218668",
      "id": "20200323-124505_1118499595_q_6WKZYWQP1W1584967376",
      "dateCreated": "Mar 23, 2020 12:45:05 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 1000
    },
    {
      "text": "%sh\nps aux | grep \"submit\"",
      "user": "namratas@qubole.com",
      "dateUpdated": "Mar 23, 2020 12:44:22 PM",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "hideControlBar": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "root     10050  0.0  0.0 115288  3104 ?        S    12:44   0:00 bash -c ps aux | grep \"submit\"\nroot     10054  0.0  0.0 110536  2088 ?        S    12:44   0:00 grep submit\nroot     19708  0.7  1.7 6967916 542120 ?      Sl   11:39   0:28 /usr/lib/jvm/java-1.8.0/bin/java -Dfile.encoding\u003dUTF-8 -Xms1024m -Xmx3123m -XX:MaxPermSize\u003d512m -Dlog4j.configuration\u003dfile:///usr/lib/zeppelin/conf/log4j.properties -Dspark.driver.extraLibraryPath\u003d/usr/lib/hadoop2/lib/native -Dspark.eventLog.compress\u003dtrue -Dspark.eventLog.enabled\u003dtrue -Dspark.executor.instances\u003d2 -Dspark.hadoop.mapreduce.fileoutputcommitter.algorithm.version\u003d2 -Dspark.hadoop.parquet.enable.summary-metadata\u003dfalse -Dspark.logConf\u003dtrue -Dspark.shuffle.reduceLocality.enabled\u003dfalse -Dspark.speculation\u003dfalse -Dspark.sql.qubole.ignoreFNFExceptions\u003dtrue -Dspark.sql.qubole.split.computation\u003dtrue -Dspark.ui.retainedJobs\u003d33 -Dspark.ui.retainedStages\u003d100 -Dspark.yarn.maxAppAttempts\u003d1 -Dspark.hadoop.fs.s3a.connection.establish.timeout\u003d5000 -Dspark.hadoop.fs.s3a.connection.maximum\u003d200 -Dspark.dynamicAllocation.enabled\u003dtrue -Dspark.executor.cores\u003d2 -Dspark.executor.memory\u003d11945M -Dspark.executor.memoryOverhead\u003d2389 -Dspark.master\u003dyarn -Dspark.qubole.listenerbus.eventlog.queue.capacity\u003d20000 -Dspark.scheduler.listenerbus.eventqueue.capacity\u003d20000 -Dspark.shuffle.service.enabled\u003dtrue -Dspark.submit.deployMode\u003dclient -Dspark.authenticate\u003dfalse -Dspark.authenticate.enableSaslEncryption\u003dfalse -Dspark.network.sasl.serverAlwaysEncrypt\u003dfalse -Dspark.qubole.internal.default.maxExecutors\u003d1000 -Dspark.shs.running.on.cluster\u003dtrue -Dspark.private.ip\u003dtrue -Dspark.qubole.forceRefreshIdleExecutor.percentage\u003d50 -Dspark.qubole.forceRefreshIdleExecutor.interval\u003d600s -Dspark.sql.qubole.directWrites.dynamicPartitionOverwrite.maxDeletionParallelism\u003d32 -Dspark.sql.qubole.mv.enable\u003dfalse -Dspark.hadoop.hive.metastore.dml.events\u003dfalse -Dspark.sql.qubole.fireInsertEvents\u003dfalse -Dspark.sql.qubole.result.formatted\u003dtrue -Dspark.qubole.shuffle.cleanup.enabled\u003dtrue -Dspark.qubole.mini.sparklens.exceptionPrintInterval\u003d120000 -Dspark.qubole.graceful.decommission.enable\u003dfalse -Dspark.shs.use.appcache\u003dtrue -Dspark.qubole.dagScheduler.changeShutdownSequence\u003dfalse -Dspark.shs.use.cluster.credentials\u003dtrue -Dspark.sql.qubole.recover.partitions\u003dtrue -Dspark.sql.qubole.partitionDiscoverer\u003dfalse -Dspark.qubole.spotloss.handle\u003dtrue -Dspark.qubole.metricRegistry.enabled\u003dtrue -Dspark.qubole.sql.hive.useDirectWrites\u003dtrue -Dspark.sql.qubole.udfPushdown.enabled\u003dtrue -Dspark.qubole.cache.parquetMetadata.enabled\u003dtrue -Dspark.qubole.cache.enabled\u003dtrue -Dspark.sql.qubole.createCustomPartitionDirInOverwrite\u003dtrue -Dspark.qubole.eventLog.hdfs.async\u003dfalse -Dspark.hadoop.hive.qubole.consistent.loadpartition\u003dfalse -Dspark.sql.qubole.metrics.enable\u003dtrue -Dspark.qubole.sendsql\u003dfalse -Dspark.sql.qubole.catalyst.normalizePredicates\u003dfalse -Dspark.qubole.forceRefreshIdleExecutor.enabled\u003dtrue -Dspark.sql.streaming.showStreamingTab\u003dtrue -Dspark.shs.publish.metrics\u003dtrue -Dspark.sql.qubole.handleCommentsWithSemicolon\u003dtrue -Dspark.hadoop.mapreduce.output.textoutputformat.overwrite\u003dtrue -Dspark.qubole.outputformat.overwriteFileInWrite\u003dtrue -Dspark.hadoop.orc.overwrite.output.file\u003dtrue -Dspark.qubole.killApplicationOnEventDrop\u003dfalse -Dspark.qubole.setIdleShutdownThreadAsDaemon\u003dfalse -Dspark.qubole.dynamicAllocation.estimateRequiredExecutorsV2\u003dtrue -Dspark.hadoop.mapreduce.use.parallelmergepaths\u003dfalse -Dspark.sql.qubole.directWrites.dynamicPartitionOverwrite.enabled\u003dfalse -Dspark.sql.qubole.directWrites.dataSourceDynamicPartitionOverwrite.enabled\u003dfalse -Dspark.sql.qubole.reorderInferredFilters\u003dtrue -Dspark.sql.qubole.list.files.v2\u003dfalse -Dspark.qubole.logMetrics\u003dtrue -Dspark.start_hs2\u003dfalse -Dspark.sql.qubole.dynamic.filter.enabled\u003dfalse -Dspark.sql.qubole.dynamicFilter.enabled\u003dtrue -Dspark.sql.streaming.directWriteEnabled\u003dtrue -Dspark.sql.qubole.result.distributedWrites\u003dfalse -Dspark.sql.qubole.computeStats.v2\u003dtrue -Dspark.qubole.dynamic.update.executors\u003dtrue -Dspark.remove_legacy_awssdk\u003dfalse -Dspark.sql.streaming.qubole.manifestCommitProtocol.handleEcIssue.enabled\u003dtrue -Dspark.sql.streaming.qubole.fileStreamSourceLog.handleEc.enabled\u003dtrue -Dspark.sql.streaming.qubole.cleanupPrevBatch.ignoreEcIssue.enabled\u003dtrue -Dspark.sql.qubole.convertHiveToS3Select\u003dfalse -Dspark.sql.qubole.convertSparkToS3Select\u003dfalse -Dspark.qubole.mini.sparklens.enabled\u003dtrue -Dspark.qubole.log.mini.sparklens.report\u003dtrue -Dspark.sql.qubole.skewJoin.enabled\u003dtrue -Dspark.qubole.userLevelConfig.enabled\u003dfalse -Dspark.qubole.event.enabled\u003dtrue -Dspark.qubole.ganglia.limitMetrics\u003dfalse -Dspark.qubole.streamingLens.enabled\u003dfalse -Dspark.qubole.abouttobelost.executor.killInterval\u003d110s -Dspark.eventLog.dir\u003dhdfs://10.182.196.34:9000/spark-history -Dspark.history.retainedApplications\u003d5 -Dspark.history.fs.update.interval\u003d10 -Dspark.yarn.historyServer.address\u003d10.182.196.34:18080 -Dspark.qubole.yarn.rm.url\u003dhttp://10.182.196.34:8088/ws/v1/cluster/nodes -Dspark.sql.hive.metastore.version\u003d1.2.1 -Dspark.sql.hive.metastore.jars\u003d/usr/lib/qubole/packages/hadoop2-2.6.0/hadoop2/etc/hadoop:/usr/lib/qubole/packages/hadoop2-2.6.0/hadoop2/share/hadoop/common/lib/*:/usr/lib/qubole/packages/hadoop2-2.6.0/hadoop2/share/hadoop/common/*:/usr/lib/qubole/packages/hadoop2-2.6.0/hadoop2/share/hadoop/hdfs:/usr/lib/qubole/packages/hadoop2-2.6.0/hadoop2/share/hadoop/hdfs/lib/*:/usr/lib/qubole/packages/hadoop2-2.6.0/hadoop2/share/hadoop/hdfs/*:/usr/lib/qubole/packages/hadoop2-2.6.0/hadoop2/share/hadoop/yarn/lib/*:/usr/lib/qubole/packages/hadoop2-2.6.0/hadoop2/share/hadoop/yarn/*:/usr/lib/qubole/packages/hadoop2-2.6.0/hadoop2/share/hadoop/mapreduce/*:/share/hadoop/tools:/usr/lib/qubole/packages/hadoop2-2.6.0/hadoop2/share/hadoop/tools/lib/*:/usr/lib/qubole/packages/hadoop2-2.6.0/hadoop2/share/hadoop/tools/*:/share/hadoop/qubole:/usr/lib/qubole/packages/hadoop2-2.6.0/hadoop2/share/hadoop/qubole/lib/*:/usr/lib/qubole/packages/hadoop2-2.6.0/hadoop2/share/hadoop/qubole/*:/contrib/capacity-scheduler/*.jar:/usr/lib/spark/lib/hive1.2/*:/usr/lib/rubix/lib/* -Dspark.hadoop.mapred.output.committer.class\u003dorg.apache.hadoop.mapred.DirectFileOutputCommitter -Dspark.hadoop.mapreduce.use.directfileoutputcommitter\u003dtrue -Dspark.hadoop.spark.sql.parquet.output.committer.class\u003dorg.apache.spark.sql.parquet.DirectParquetOutputCommitter -Dspark.qubole.cache.redisHost\u003d10.182.196.34 -Dspark.rolling.log4j.properties\u003d/usr/lib/spark/conf/log4j_rolling.properties -Dspark.qubole.fast.startup\u003dtrue -Dspark.yarn.jars\u003dlocal://usr/lib/spark/assembly/target/scala-2.11/jars/* -Dspark.scheduler.maxRegisteredResourcesWaitingTime\u003d0s -Dspark.hadoop.yarn.timeline-service.enabled\u003dfalse -Dspark.qubole.cluster.id\u003d605 -Dspark.qubole.account.id\u003d85 -Dspark.qubole.cluster.token\u003da8be23f49785479688a02db714ea5977aee2a22d4389487781b1cce89023e5e7 -Dspark.local.dir\u003d/media/ephemeral0/spark/tmp -Dzeppelin.log.file\u003d/usr/lib/zeppelin/logs/zeppelin--ip-10-182-196-34.log -Dhttps.protocols\u003dTLSv1.1,TLSv1.2 -Dhttp.proxyHost\u003d%INTERNET_PROXY_SERVER% -Dhttp.proxyPort\u003d -Dhttps.proxyHost\u003d%INTERNET_PROXY_SERVER% -Dhttps.proxyPort\u003d -Dhttp.auth.preference\u003dbasic -Djdk.http.auth.tunneling.disabledSchemes\u003d\"\" -Dspark.driver.extraJavaOptions\u003d-Djava.net.preferIPv4Stack\u003dtrue -XX:ReservedCodeCacheSize\u003d100m -XX:+UseCodeCacheFlushing -XX:+UseG1GC -Dspark.executor.extraJavaOptions\u003d-Djava.net.preferIPv4Stack\u003dtrue -XX:ReservedCodeCacheSize\u003d100m -XX:+UseCodeCacheFlushing -XX:+UseG1GC -cp ::/usr/lib/zeppelin/zeppelin-server/target/lib/*:/usr/lib/zeppelin/zeppelin-zengine/target/lib/*:/usr/lib/zeppelin/zeppelin-interpreter/target/lib/*:/usr/lib/zeppelin/lib/*:/usr/lib/zeppelin/*::/usr/lib/zeppelin/conf:/usr/lib/zeppelin/zeppelin-interpreter/target/classes:/usr/lib/hadoop2/etc/hadoop/ org.apache.zeppelin.server.ZeppelinServer\n"
          }
        ]
      },
      "apps": [],
      "version": "v1",
      "jobName": "paragraph_1584967404464_250117914",
      "id": "20200323-124324_1147016397_q_6WKZYWQP1W1584967376",
      "dateCreated": "Mar 23, 2020 12:43:24 PM",
      "dateSubmitted": "Mar 23, 2020 12:44:22 PM",
      "dateStarted": "Mar 23, 2020 12:44:22 PM",
      "dateFinished": "Mar 23, 2020 12:44:22 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 1000
    },
    {
      "text": "%sh\n",
      "user": "namratas@qubole.com",
      "dateUpdated": "Mar 23, 2020 12:43:54 PM",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "version": "v0",
      "jobName": "paragraph_1584967434869_-612200221",
      "id": "20200323-124354_975737132_q_6WKZYWQP1W1584967376",
      "dateCreated": "Mar 23, 2020 12:43:54 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 1000
    }
  ],
  "name": "check_jupy",
  "id": "6WKZYWQP1W1584967376",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "isDashboard": false,
    "defaultLang": "spark"
  },
  "info": {
    "runAllInProgress": false
  },
  "source": "FCN"
}